{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jake314jake/facial-recognition/blob/main/CNN%26SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4J2ixnL-qTd",
        "outputId": "38bd0ccb-b229-49df-8c35-6ad6b116ee58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI3nydKCFyx9",
        "outputId": "8c80e819-82fe-4c5e-d83b-0bf1a9d3483f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.25.2)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ],
      "source": [
        "! sudo pip install mtcnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYx8Mvt6GJPa",
        "outputId": "52f30fc8-3314-426a-8cf9-803f4cf95377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/0LFWtest.rar\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/drive/MyDrive/0LFWtest.rar or\n",
            "        /content/drive/MyDrive/0LFWtest.rar.zip, and cannot find /content/drive/MyDrive/0LFWtest.rar.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "! unzip '/content/drive/MyDrive/0LFWtest.rar'  '/content/drive/MyDrive/0LFWtrain.rar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBtP9SZWH-FT",
        "outputId": "627fdd9b-5716-4df8-cb47-921686995cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install  keras numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1znBSJSGAU3"
      },
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(160, 160)):\n",
        "    # load image from file\n",
        "    image = Image.open(filename)\n",
        "    # convert to RGB, if needed\n",
        "    image = image.convert('RGB')\n",
        "    # convert to array\n",
        "    pixels = asarray(image)\n",
        "    # create the detector, using default weights\n",
        "    detector = MTCNN()\n",
        "    # detect faces in the image\n",
        "    results = detector.detect_faces(pixels)\n",
        "    # extract the bounding box from the first face\n",
        "    x1, y1, width, height = results[0]['box']\n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    # extract the face\n",
        "    face = pixels[y1:y2, x1:x2]\n",
        "    # resize pixels to the model size\n",
        "    image = Image.fromarray(face)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = asarray(image)\n",
        "    return face_array\n",
        "\n",
        "# load images and extract faces for all images in a directory\n",
        "def load_faces(directory):\n",
        "    faces = list()\n",
        "    # enumerate files\n",
        "    for filename in listdir(directory):\n",
        "        # path\n",
        "        path = directory + filename\n",
        "        # get face\n",
        "        face = extract_face(path)\n",
        "        # store\n",
        "        faces.append(face)\n",
        "    return faces\n",
        "\n",
        "# load a dataset that contains one subdir for each class that in turn contains images\n",
        "def load_dataset(directory):\n",
        "    X, y = list(), list()\n",
        "    # enumerate folders, on per class\n",
        "    for subdir in listdir(directory):\n",
        "        # path\n",
        "        path = directory + subdir + '/'\n",
        "        # skip any files that might be in the dir\n",
        "        if not isdir(path):\n",
        "            continue\n",
        "        # load all faces in the subdirectory\n",
        "        faces = load_faces(path)\n",
        "        # create labels\n",
        "        labels = [subdir for _ in range(len(faces))]\n",
        "        # summarize progress\n",
        "        print('>loaded %d examples for person: %s' % (len(faces), subdir))\n",
        "        # store\n",
        "        X.extend(faces)\n",
        "        y.extend(labels)\n",
        "    return asarray(X), asarray(y)\n",
        "\n",
        "# load train dataset\n",
        "dir_loc = input(\"Enter the path of the directory with training data: \")\n",
        "dir_loc.replace('\\\\', '/')\n",
        "dir_loc += '/'\n",
        "trainX, trainy = load_dataset(dir_loc)\n",
        "print(trainX.shape, trainy.shape)\n",
        "# load test dataset\n",
        "dir_loc = input(\"Enter the path of the directory with testing data: \")\n",
        "dir_loc.replace('\\\\', '/')\n",
        "dir_loc += '/'\n",
        "testX, testy = load_dataset(dir_loc)\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('init_face_array.npz', trainX, trainy, testX, testy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1JX1V-MLe5Y",
        "outputId": "448ed607-c51e-42c6-907e-63d71ca62aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_facenet\n",
            "  Downloading keras-facenet-0.3.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (from keras_facenet) (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn->keras_facenet) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn->keras_facenet) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn->keras_facenet) (1.25.2)\n",
            "Building wheels for collected packages: keras_facenet\n",
            "  Building wheel for keras_facenet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10368 sha256=14b889c91011720ef87ade5c6831351bd20518dc9e961b4ec0293afe3caacc4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/d8/a9/85cf04ea29321d2afcb82c0caaafdca9195385f9d68cbc7185\n",
            "Successfully built keras_facenet\n",
            "Installing collected packages: keras_facenet\n",
            "Successfully installed keras_facenet-0.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_facenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c4caQ13RVPt",
        "outputId": "258e8414-b29b-416e-a7ee-dfb35fdbc15a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_facenet.FaceNet at 0x7f6dd8a31780>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from keras_facenet import FaceNet\n",
        "model =FaceNet()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PBzhsBRHX-z"
      },
      "outputs": [],
      "source": [
        "# calculate a face embedding for each face in the dataset using facenet\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "#from numpy import asarray\n",
        "#from numpy import savez_compressed\n",
        "from keras.models import load_model\n",
        "\n",
        "# get the face embedding for one face\n",
        "def get_embedding(model, face_pixels):\n",
        "    # scale pixel values\n",
        "    face_pixels = face_pixels.astype('float32')\n",
        "    # standardize pixel values across channels (global)\n",
        "    # transform face into one sample\n",
        "    samples = expand_dims(face_pixels, axis=0)\n",
        "    # make prediction to get embedding\n",
        "    yhat = model.embeddings(samples)\n",
        "    return yhat[0]\n",
        "\n",
        "# load the face dataset\n",
        "data = load('init_face_array.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "# load the facenet model\n",
        "\n",
        "# convert each face in the train set to an embedding\n",
        "newTrainX = list()\n",
        "for face_pixels in trainX:\n",
        "    embedding = get_embedding(model, face_pixels)\n",
        "    newTrainX.append(embedding)\n",
        "newTrainX = asarray(newTrainX)\n",
        "print(newTrainX.shape)\n",
        "# convert each face in the test set to an embedding\n",
        "newTestX = list()\n",
        "for face_pixels in testX:\n",
        "    embedding = get_embedding(model, face_pixels)\n",
        "    newTestX.append(embedding)\n",
        "newTestX = asarray(newTestX)\n",
        "print(newTestX.shape)\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('faces-embeddings.npz', newTrainX, trainy, newTestX, testy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "e-tB9fXsNZXA",
        "outputId": "65094a12-b83b-46fb-eb24-473bd3d6fd99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded:  (960, 512) (960,) (480, 512) (480,)\n",
            "Dataset: train=960, test=480\n",
            "Accuracy: train=99.479, test=96.667\n",
            "Predicted: Venus_Williams (13.115)\n",
            "Expected: Venus_Williams\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"print(random_face_pixels.shape)\\npyplot.imshow(random_face_pixels)\\ntitle = '%s (%.3f)' % (predict_names[0], class_probability)\\npyplot.title(title)\\npyplot.show()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from random import choice\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "# load dataset\n",
        "data = load('faces-embeddings.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "print('Dataset: train=%d, test=%d' % (trainX.shape[0], testX.shape[0]))\n",
        "# normalize input vectors\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "# label encode targets\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "# fit model\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "# predict\n",
        "yhat_train = model.predict(trainX)\n",
        "yhat_test = model.predict(testX)\n",
        "# score\n",
        "score_train = accuracy_score(trainy, yhat_train)\n",
        "score_test = accuracy_score(testy, yhat_test)\n",
        "# summarize\n",
        "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))\n",
        "#####################################################################################################################\n",
        "#####################################################################################################################\n",
        "#####################################################################################################################\n",
        "#####################################################################################################################\n",
        "testX_faces = data['arr_2']\n",
        "# test model on a random example from the test dataset\n",
        "selection = choice([i for i in range(testX.shape[0])])\n",
        "#selection = 5\n",
        "random_face_pixels = testX_faces[selection]\n",
        "random_face_emb = testX[selection]\n",
        "random_face_class = testy[selection]\n",
        "random_face_name = out_encoder.inverse_transform([random_face_class])\n",
        "# prediction for the face\n",
        "samples = expand_dims(random_face_emb, axis=0)\n",
        "yhat_class = model.predict(samples)\n",
        "yhat_prob = model.predict_proba(samples)\n",
        "# get name\n",
        "class_index = yhat_class[0]\n",
        "class_probability = yhat_prob[0,class_index] * 100\n",
        "predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
        "print('Expected: %s' % random_face_name[0])\n",
        "\n",
        "\n",
        "#print the image with the predicted and expected output, please fork and help\n",
        "'''print(random_face_pixels.shape)\n",
        "pyplot.imshow(random_face_pixels)\n",
        "title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "pyplot.title(title)\n",
        "pyplot.show()'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbj4Xg3V5nmh",
        "outputId": "cd246a2d-bb7d-4758-da8d-15fd8611a2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 92720\n",
            "drwxr-xr-x 98 root root     4096 Feb 22 15:09 0LFWtest\n",
            "drwxr-xr-x 98 root root     4096 Feb 22 15:09 0LFWtrain\n",
            "drwxr-xr-x  2 root root     4096 Feb 22 21:24 data\n",
            "drwx------  5 root root     4096 Feb 22 21:18 drive\n",
            "-rw-r--r--  1 root root  2737382 Feb 22 22:16 faces-embeddings.npz\n",
            "-rw-r--r--  1 root root 92184325 Feb 22 22:12 init_face_array.npz\n",
            "drwxr-xr-x  1 root root     4096 Feb 21 14:21 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "yncb2iBi58-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/init_face_array.npz' '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "hGbtGt_-6RWK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNfdlbxU7LKk/CnFp6NbwVT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}